import { Pool, PoolClient } from 'pg';
import {
  StoragePort,
  StoredAclEntry,
  AuditQueryOptions,
  AuditStats,
  StoredClientSnapshot,
  ClientSnapshotQueryOptions,
  ClientTimeSeriesPoint,
  ClientAnalyticsStats,
  StoredAnomalyEvent,
  StoredCorrelatedGroup,
  AnomalyQueryOptions,
  AnomalyStats,
  KeyPatternSnapshot,
  KeyPatternQueryOptions,
  KeyAnalyticsSummary,
  AppSettings,
  SettingsUpdateRequest,
  Webhook,
  WebhookDelivery,
  WebhookEventType,
  DeliveryStatus,
  StoredSlowLogEntry,
  SlowLogQueryOptions,
  StoredCommandLogEntry,
  CommandLogQueryOptions,
  CommandLogType,
} from '../../common/interfaces/storage-port.interface';

export interface PostgresAdapterConfig {
  connectionString: string;
}

export class PostgresAdapter implements StoragePort {
  private pool: Pool | null = null;
  private ready: boolean = false;

  constructor(private config: PostgresAdapterConfig) { }

  async initialize(): Promise<void> {
    try {
      this.pool = new Pool({
        connectionString: this.config.connectionString,
      });

      // Test connection
      const client = await this.pool.connect();
      client.release();

      // Create schema
      await this.createSchema();
      this.ready = true;
    } catch (error) {
      this.ready = false;
      throw new Error(
        `Failed to initialize PostgreSQL: ${error instanceof Error ? error.message : 'Unknown error'}`,
      );
    }
  }

  async close(): Promise<void> {
    if (this.pool) {
      await this.pool.end();
      this.pool = null;
      this.ready = false;
    }
  }

  isReady(): boolean {
    return this.ready && this.pool !== null;
  }

  async saveAclEntries(entries: StoredAclEntry[]): Promise<number> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    if (entries.length === 0) {
      return 0;
    }

    const values: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    for (const entry of entries) {
      values.push(
        `($${paramIndex}, $${paramIndex + 1}, $${paramIndex + 2}, $${paramIndex + 3}, $${paramIndex + 4}, $${paramIndex + 5}, $${paramIndex + 6}, $${paramIndex + 7}, $${paramIndex + 8}, $${paramIndex + 9}, $${paramIndex + 10}, $${paramIndex + 11})`,
      );
      params.push(
        entry.count,
        entry.reason,
        entry.context,
        entry.object,
        entry.username,
        entry.ageSeconds,
        entry.clientInfo,
        entry.timestampCreated,
        entry.timestampLastUpdated,
        entry.capturedAt,
        entry.sourceHost,
        entry.sourcePort,
      );
      paramIndex += 12;
    }

    const query = `
      INSERT INTO acl_audit (
        count, reason, context, object, username, age_seconds, client_info,
        timestamp_created, timestamp_last_updated, captured_at, source_host, source_port
      ) VALUES ${values.join(', ')}
      ON CONFLICT (timestamp_created, username, object, reason, source_host, source_port)
      DO UPDATE SET
        count = EXCLUDED.count,
        age_seconds = EXCLUDED.age_seconds,
        timestamp_last_updated = EXCLUDED.timestamp_last_updated,
        captured_at = EXCLUDED.captured_at
    `;

    await this.pool.query(query, params);
    return entries.length;
  }

  async getAclEntries(options: AuditQueryOptions = {}): Promise<StoredAclEntry[]> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    const conditions: string[] = [];
    const params: (string | number)[] = [];
    let paramIndex = 1;

    if (options.username) {
      conditions.push(`username = $${paramIndex++}`);
      params.push(options.username);
    }

    if (options.reason) {
      conditions.push(`reason = $${paramIndex++}`);
      params.push(options.reason);
    }

    if (options.startTime) {
      conditions.push(`captured_at >= $${paramIndex++}`);
      params.push(options.startTime);
    }

    if (options.endTime) {
      conditions.push(`captured_at <= $${paramIndex++}`);
      params.push(options.endTime);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';
    const limit = options.limit ?? 100;
    const offset = options.offset ?? 0;

    const query = `
      SELECT * FROM acl_audit
      ${whereClause}
      ORDER BY captured_at DESC, id DESC
      LIMIT $${paramIndex} OFFSET $${paramIndex + 1}
    `;

    params.push(limit, offset);

    const result = await this.pool.query(query, params);
    return result.rows.map((row) => ({
      id: row.id,
      count: row.count,
      reason: row.reason,
      context: row.context,
      object: row.object,
      username: row.username,
      ageSeconds: row.age_seconds,
      clientInfo: row.client_info,
      timestampCreated: row.timestamp_created,
      timestampLastUpdated: row.timestamp_last_updated,
      capturedAt: row.captured_at,
      sourceHost: row.source_host,
      sourcePort: row.source_port,
    }));
  }

  async getAuditStats(startTime?: number, endTime?: number): Promise<AuditStats> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    const conditions: string[] = [];
    const params: number[] = [];
    let paramIndex = 1;

    if (startTime) {
      conditions.push(`captured_at >= $${paramIndex++}`);
      params.push(startTime);
    }

    if (endTime) {
      conditions.push(`captured_at <= $${paramIndex++}`);
      params.push(endTime);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';

    const totalResult = await this.pool.query(
      `SELECT COUNT(*) as count FROM acl_audit ${whereClause}`,
      params,
    );

    const uniqueUsersResult = await this.pool.query(
      `SELECT COUNT(DISTINCT username) as count FROM acl_audit ${whereClause}`,
      params,
    );

    const byReasonResult = await this.pool.query(
      `SELECT reason, COUNT(*) as count FROM acl_audit ${whereClause} GROUP BY reason`,
      params,
    );

    const byUserResult = await this.pool.query(
      `SELECT username, COUNT(*) as count FROM acl_audit ${whereClause} GROUP BY username`,
      params,
    );

    const timeRangeResult = await this.pool.query(
      `SELECT MIN(captured_at) as earliest, MAX(captured_at) as latest FROM acl_audit ${whereClause}`,
      params,
    );

    const entriesByReason: Record<string, number> = {};
    for (const row of byReasonResult.rows) {
      entriesByReason[row.reason] = parseInt(row.count);
    }

    const entriesByUser: Record<string, number> = {};
    for (const row of byUserResult.rows) {
      entriesByUser[row.username] = parseInt(row.count);
    }

    const timeRange =
      timeRangeResult.rows[0].earliest !== null && timeRangeResult.rows[0].latest !== null
        ? {
          earliest: parseInt(timeRangeResult.rows[0].earliest),
          latest: parseInt(timeRangeResult.rows[0].latest),
        }
        : null;

    return {
      totalEntries: parseInt(totalResult.rows[0].count),
      uniqueUsers: parseInt(uniqueUsersResult.rows[0].count),
      entriesByReason,
      entriesByUser,
      timeRange,
    };
  }

  async pruneOldEntries(olderThanTimestamp: number): Promise<number> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    const result = await this.pool.query('DELETE FROM acl_audit WHERE captured_at < $1', [
      olderThanTimestamp,
    ]);

    return result.rowCount || 0;
  }

  async saveClientSnapshot(clients: StoredClientSnapshot[]): Promise<number> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    if (clients.length === 0) {
      return 0;
    }

    const values: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    for (const client of clients) {
      values.push(
        `($${paramIndex}, $${paramIndex + 1}, $${paramIndex + 2}, $${paramIndex + 3}, $${paramIndex + 4}, $${paramIndex + 5}, $${paramIndex + 6}, $${paramIndex + 7}, $${paramIndex + 8}, $${paramIndex + 9}, $${paramIndex + 10}, $${paramIndex + 11}, $${paramIndex + 12}, $${paramIndex + 13}, $${paramIndex + 14}, $${paramIndex + 15}, $${paramIndex + 16}, $${paramIndex + 17}, $${paramIndex + 18})`,
      );
      params.push(
        client.clientId,
        client.addr,
        client.name || null,
        client.user || null,
        client.db,
        client.cmd || null,
        client.age,
        client.idle,
        client.flags || null,
        client.sub,
        client.psub,
        client.qbuf,
        client.qbufFree,
        client.obl,
        client.oll,
        client.omem,
        client.capturedAt,
        client.sourceHost,
        client.sourcePort,
      );
      paramIndex += 19;
    }

    const query = `
      INSERT INTO client_snapshots (
        client_id, addr, name, user_name, db, cmd, age, idle, flags,
        sub, psub, qbuf, qbuf_free, obl, oll, omem,
        captured_at, source_host, source_port
      ) VALUES ${values.join(', ')}
    `;

    await this.pool.query(query, params);
    return clients.length;
  }

  async getClientSnapshots(options: ClientSnapshotQueryOptions = {}): Promise<StoredClientSnapshot[]> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    const conditions: string[] = [];
    const params: (string | number)[] = [];
    let paramIndex = 1;

    if (options.clientName) {
      conditions.push(`name = $${paramIndex++}`);
      params.push(options.clientName);
    }

    if (options.user) {
      conditions.push(`user_name = $${paramIndex++}`);
      params.push(options.user);
    }

    if (options.addr) {
      if (options.addr.includes('%')) {
        conditions.push(`addr LIKE $${paramIndex++}`);
      } else {
        conditions.push(`addr = $${paramIndex++}`);
      }
      params.push(options.addr);
    }

    if (options.startTime) {
      conditions.push(`captured_at >= $${paramIndex++}`);
      params.push(options.startTime);
    }

    if (options.endTime) {
      conditions.push(`captured_at <= $${paramIndex++}`);
      params.push(options.endTime);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';
    const limit = options.limit ?? 100;
    const offset = options.offset ?? 0;

    const query = `
      SELECT * FROM client_snapshots
      ${whereClause}
      ORDER BY captured_at DESC, id DESC
      LIMIT $${paramIndex} OFFSET $${paramIndex + 1}
    `;

    params.push(limit, offset);

    const result = await this.pool.query(query, params);
    return result.rows.map(this.mapClientRow);
  }

  async getClientTimeSeries(
    startTime: number,
    endTime: number,
    bucketSizeMs: number = 60000,
  ): Promise<ClientTimeSeriesPoint[]> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    const query = `
      SELECT
        (captured_at / $1 * $1) as bucket_time,
        COUNT(*) as total_connections,
        name,
        user_name,
        addr
      FROM client_snapshots
      WHERE captured_at >= $2 AND captured_at <= $3
      GROUP BY bucket_time, name, user_name, addr
      ORDER BY bucket_time
    `;

    const result = await this.pool.query(query, [bucketSizeMs, startTime, endTime]);

    const pointsMap = new Map<number, ClientTimeSeriesPoint>();

    for (const row of result.rows) {
      const bucketTime = parseInt(row.bucket_time);
      if (!pointsMap.has(bucketTime)) {
        pointsMap.set(bucketTime, {
          timestamp: bucketTime,
          totalConnections: 0,
          byName: {},
          byUser: {},
          byAddr: {},
        });
      }

      const point = pointsMap.get(bucketTime)!;
      point.totalConnections += parseInt(row.total_connections);

      if (row.name) {
        point.byName[row.name] = (point.byName[row.name] || 0) + 1;
      }
      if (row.user_name) {
        point.byUser[row.user_name] = (point.byUser[row.user_name] || 0) + 1;
      }
      const ip = row.addr.split(':')[0];
      point.byAddr[ip] = (point.byAddr[ip] || 0) + 1;
    }

    return Array.from(pointsMap.values()).sort((a, b) => a.timestamp - b.timestamp);
  }

  async getClientAnalyticsStats(startTime?: number, endTime?: number): Promise<ClientAnalyticsStats> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    const conditions: string[] = [];
    const params: number[] = [];
    let paramIndex = 1;

    if (startTime) {
      conditions.push(`captured_at >= $${paramIndex++}`);
      params.push(startTime);
    }

    if (endTime) {
      conditions.push(`captured_at <= $${paramIndex++}`);
      params.push(endTime);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';

    // Get latest timestamp
    const latestResult = await this.pool.query(
      `SELECT MAX(captured_at) as latest FROM client_snapshots ${whereClause}`,
      params,
    );
    const latestTimestamp = latestResult.rows[0].latest;

    const currentConditions = latestTimestamp ? [...conditions, `captured_at = $${paramIndex++}`] : conditions;
    const currentParams = latestTimestamp ? [...params, latestTimestamp] : params;
    const currentWhereClause = currentConditions.length > 0 ? `WHERE ${currentConditions.join(' AND ')}` : '';

    const currentConnectionsResult = await this.pool.query(
      `SELECT COUNT(*) as count FROM client_snapshots ${currentWhereClause}`,
      currentParams,
    );

    const peakResult = await this.pool.query(
      `
      SELECT captured_at, COUNT(*) as count
      FROM client_snapshots ${whereClause}
      GROUP BY captured_at
      ORDER BY count DESC
      LIMIT 1
    `,
      params,
    );

    const uniqueStatsResult = await this.pool.query(
      `
      SELECT
        COUNT(DISTINCT name) as unique_names,
        COUNT(DISTINCT user_name) as unique_users,
        COUNT(DISTINCT SPLIT_PART(addr, ':', 1)) as unique_ips
      FROM client_snapshots ${whereClause}
    `,
      params,
    );

    // Connections by name
    const byNameResult = await this.pool.query(
      `
      SELECT name, COUNT(*) as total, AVG(age) as avg_age
      FROM client_snapshots ${whereClause}
      GROUP BY name
    `,
      params,
    );

    const connectionsByName: Record<string, { current: number; peak: number; avgAge: number }> = {};

    for (const row of byNameResult.rows) {
      if (row.name) {
        const namePeakParams = [...params, row.name];
        const namePeakResult = await this.pool.query(
          `
          SELECT COUNT(*) as count
          FROM client_snapshots
          WHERE name = $${params.length + 1} ${whereClause ? 'AND ' + whereClause.substring(6) : ''}
          GROUP BY captured_at
          ORDER BY count DESC
          LIMIT 1
        `,
          namePeakParams,
        );

        const nameCurrentParams = [...currentParams, row.name];
        const nameCurrentResult = await this.pool.query(
          `
          SELECT COUNT(*) as count
          FROM client_snapshots
          WHERE name = $${currentParams.length + 1} ${currentWhereClause ? 'AND ' + currentWhereClause.substring(6) : ''}
        `,
          nameCurrentParams,
        );

        connectionsByName[row.name] = {
          current: parseInt(nameCurrentResult.rows[0]?.count || '0'),
          peak: parseInt(namePeakResult.rows[0]?.count || '0'),
          avgAge: parseFloat(row.avg_age),
        };
      }
    }

    // Connections by user
    const byUserResult = await this.pool.query(
      `SELECT user_name, COUNT(*) as total FROM client_snapshots ${whereClause} GROUP BY user_name`,
      params,
    );

    const connectionsByUser: Record<string, { current: number; peak: number }> = {};

    for (const row of byUserResult.rows) {
      if (row.user_name) {
        const userPeakParams = [...params, row.user_name];
        const userPeakResult = await this.pool.query(
          `
          SELECT COUNT(*) as count
          FROM client_snapshots
          WHERE user_name = $${params.length + 1} ${whereClause ? 'AND ' + whereClause.substring(6) : ''}
          GROUP BY captured_at
          ORDER BY count DESC
          LIMIT 1
        `,
          userPeakParams,
        );

        const userCurrentParams = [...currentParams, row.user_name];
        const userCurrentResult = await this.pool.query(
          `
          SELECT COUNT(*) as count
          FROM client_snapshots
          WHERE user_name = $${currentParams.length + 1} ${currentWhereClause ? 'AND ' + currentWhereClause.substring(6) : ''}
        `,
          userCurrentParams,
        );

        connectionsByUser[row.user_name] = {
          current: parseInt(userCurrentResult.rows[0]?.count || '0'),
          peak: parseInt(userPeakResult.rows[0]?.count || '0'),
        };
      }
    }

    // Connections by user and name
    const byUserAndNameResult = await this.pool.query(
      `
      SELECT user_name, name, COUNT(*) as total, AVG(age) as avg_age
      FROM client_snapshots ${whereClause}
      GROUP BY user_name, name
    `,
      params,
    );

    const connectionsByUserAndName: Record<string, { user: string; name: string; current: number; peak: number; avgAge: number }> = {};

    for (const row of byUserAndNameResult.rows) {
      const key = `${row.user_name}:${row.name}`;

      const combinedPeakParams = [...params, row.user_name, row.name];
      const combinedPeakResult = await this.pool.query(
        `
        SELECT COUNT(*) as count
        FROM client_snapshots
        WHERE user_name = $${params.length + 1} AND name = $${params.length + 2} ${whereClause ? 'AND ' + whereClause.substring(6) : ''}
        GROUP BY captured_at
        ORDER BY count DESC
        LIMIT 1
      `,
        combinedPeakParams,
      );

      const combinedCurrentParams = [...currentParams, row.user_name, row.name];
      const combinedCurrentResult = await this.pool.query(
        `
        SELECT COUNT(*) as count
        FROM client_snapshots
        WHERE user_name = $${currentParams.length + 1} AND name = $${currentParams.length + 2} ${currentWhereClause ? 'AND ' + currentWhereClause.substring(6) : ''}
      `,
        combinedCurrentParams,
      );

      connectionsByUserAndName[key] = {
        user: row.user_name,
        name: row.name,
        current: parseInt(combinedCurrentResult.rows[0]?.count || '0'),
        peak: parseInt(combinedPeakResult.rows[0]?.count || '0'),
        avgAge: parseFloat(row.avg_age),
      };
    }

    const timeRangeResult = await this.pool.query(
      `SELECT MIN(captured_at) as earliest, MAX(captured_at) as latest FROM client_snapshots ${whereClause}`,
      params,
    );

    const timeRange =
      timeRangeResult.rows[0].earliest !== null && timeRangeResult.rows[0].latest !== null
        ? {
          earliest: parseInt(timeRangeResult.rows[0].earliest),
          latest: parseInt(timeRangeResult.rows[0].latest),
        }
        : null;

    return {
      currentConnections: parseInt(currentConnectionsResult.rows[0].count),
      peakConnections: parseInt(peakResult.rows[0]?.count || '0'),
      peakTimestamp: parseInt(peakResult.rows[0]?.captured_at || '0'),
      uniqueClientNames: parseInt(uniqueStatsResult.rows[0].unique_names),
      uniqueUsers: parseInt(uniqueStatsResult.rows[0].unique_users),
      uniqueIps: parseInt(uniqueStatsResult.rows[0].unique_ips),
      connectionsByName,
      connectionsByUser,
      connectionsByUserAndName,
      timeRange,
    };
  }

  async getClientConnectionHistory(
    identifier: { name?: string; user?: string; addr?: string },
    startTime?: number,
    endTime?: number,
  ): Promise<StoredClientSnapshot[]> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    const conditions: string[] = [];
    const params: (string | number)[] = [];
    let paramIndex = 1;

    if (identifier.name) {
      conditions.push(`name = $${paramIndex++}`);
      params.push(identifier.name);
    }

    if (identifier.user) {
      conditions.push(`user_name = $${paramIndex++}`);
      params.push(identifier.user);
    }

    if (identifier.addr) {
      conditions.push(`addr = $${paramIndex++}`);
      params.push(identifier.addr);
    }

    if (startTime) {
      conditions.push(`captured_at >= $${paramIndex++}`);
      params.push(startTime);
    }

    if (endTime) {
      conditions.push(`captured_at <= $${paramIndex++}`);
      params.push(endTime);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';

    const query = `
      SELECT * FROM client_snapshots
      ${whereClause}
      ORDER BY captured_at ASC
    `;

    const result = await this.pool.query(query, params);
    return result.rows.map(this.mapClientRow);
  }

  async pruneOldClientSnapshots(olderThanTimestamp: number): Promise<number> {
    if (!this.pool) {
      throw new Error('Database not initialized');
    }

    const result = await this.pool.query('DELETE FROM client_snapshots WHERE captured_at < $1', [
      olderThanTimestamp,
    ]);

    return result.rowCount || 0;
  }

  private mapClientRow(row: any): StoredClientSnapshot {
    return {
      id: row.id,
      clientId: row.client_id,
      addr: row.addr,
      name: row.name,
      user: row.user_name,
      db: row.db,
      cmd: row.cmd,
      age: row.age,
      idle: row.idle,
      flags: row.flags,
      sub: row.sub,
      psub: row.psub,
      qbuf: row.qbuf,
      qbufFree: row.qbuf_free,
      obl: row.obl,
      oll: row.oll,
      omem: row.omem,
      capturedAt: row.captured_at,
      sourceHost: row.source_host,
      sourcePort: row.source_port,
    };
  }

  private async createSchema(): Promise<void> {
    if (!this.pool) {
      return;
    }

    await this.pool.query(`
      CREATE TABLE IF NOT EXISTS acl_audit (
        id SERIAL PRIMARY KEY,
        count INTEGER NOT NULL,
        reason TEXT NOT NULL,
        context TEXT NOT NULL,
        object TEXT NOT NULL,
        username TEXT NOT NULL,
        age_seconds DOUBLE PRECISION NOT NULL,
        client_info TEXT NOT NULL,
        timestamp_created BIGINT NOT NULL,
        timestamp_last_updated BIGINT NOT NULL,
        captured_at BIGINT NOT NULL,
        source_host TEXT NOT NULL,
        source_port INTEGER NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(timestamp_created, username, object, reason, source_host, source_port)
      );

      CREATE INDEX IF NOT EXISTS idx_acl_username ON acl_audit(username);
      CREATE INDEX IF NOT EXISTS idx_acl_reason ON acl_audit(reason);
      CREATE INDEX IF NOT EXISTS idx_acl_captured_at ON acl_audit(captured_at);
      CREATE INDEX IF NOT EXISTS idx_acl_timestamp_created ON acl_audit(timestamp_created);

      CREATE TABLE IF NOT EXISTS client_snapshots (
        id SERIAL PRIMARY KEY,
        client_id TEXT NOT NULL,
        addr TEXT NOT NULL,
        name TEXT,
        user_name TEXT,
        db INTEGER NOT NULL,
        cmd TEXT,
        age INTEGER NOT NULL,
        idle INTEGER NOT NULL,
        flags TEXT,
        sub INTEGER NOT NULL DEFAULT 0,
        psub INTEGER NOT NULL DEFAULT 0,
        qbuf INTEGER NOT NULL DEFAULT 0,
        qbuf_free INTEGER NOT NULL DEFAULT 0,
        obl INTEGER NOT NULL DEFAULT 0,
        oll INTEGER NOT NULL DEFAULT 0,
        omem INTEGER NOT NULL DEFAULT 0,
        captured_at BIGINT NOT NULL,
        source_host TEXT NOT NULL,
        source_port INTEGER NOT NULL
      );

      CREATE INDEX IF NOT EXISTS idx_client_captured_at ON client_snapshots(captured_at);
      CREATE INDEX IF NOT EXISTS idx_client_name ON client_snapshots(name);
      CREATE INDEX IF NOT EXISTS idx_client_user ON client_snapshots(user_name);
      CREATE INDEX IF NOT EXISTS idx_client_addr ON client_snapshots(addr);
      CREATE INDEX IF NOT EXISTS idx_client_idle ON client_snapshots(idle) WHERE idle > 300;
      CREATE INDEX IF NOT EXISTS idx_client_qbuf ON client_snapshots(qbuf) WHERE qbuf > 1000000;
      CREATE INDEX IF NOT EXISTS idx_client_omem ON client_snapshots(omem) WHERE omem > 10000000;
      CREATE INDEX IF NOT EXISTS idx_client_cmd ON client_snapshots(cmd);
      CREATE INDEX IF NOT EXISTS idx_client_captured_at_cmd ON client_snapshots(captured_at, cmd);

      -- Anomaly Events Table
      CREATE TABLE IF NOT EXISTS anomaly_events (
        id UUID PRIMARY KEY,
        timestamp BIGINT NOT NULL,
        metric_type VARCHAR(50) NOT NULL,
        anomaly_type VARCHAR(20) NOT NULL,
        severity VARCHAR(20) NOT NULL,
        value DOUBLE PRECISION NOT NULL,
        baseline DOUBLE PRECISION NOT NULL,
        std_dev DOUBLE PRECISION NOT NULL,
        z_score DOUBLE PRECISION NOT NULL,
        threshold DOUBLE PRECISION NOT NULL,
        message TEXT NOT NULL,
        correlation_id UUID,
        related_metrics TEXT[],
        resolved BOOLEAN DEFAULT FALSE,
        resolved_at BIGINT,
        duration_ms BIGINT,
        source_host VARCHAR(255),
        source_port INTEGER,
        created_at TIMESTAMPTZ DEFAULT NOW()
      );

      CREATE INDEX IF NOT EXISTS idx_anomaly_events_timestamp ON anomaly_events(timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_anomaly_events_severity ON anomaly_events(severity, timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_anomaly_events_metric ON anomaly_events(metric_type, timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_anomaly_events_correlation ON anomaly_events(correlation_id);
      CREATE INDEX IF NOT EXISTS idx_anomaly_events_unresolved ON anomaly_events(resolved, timestamp DESC) WHERE NOT resolved;

      -- Correlated Anomaly Groups Table
      CREATE TABLE IF NOT EXISTS correlated_anomaly_groups (
        correlation_id UUID PRIMARY KEY,
        timestamp BIGINT NOT NULL,
        pattern VARCHAR(50) NOT NULL,
        severity VARCHAR(20) NOT NULL,
        diagnosis TEXT NOT NULL,
        recommendations TEXT[],
        anomaly_count INTEGER NOT NULL,
        metric_types TEXT[],
        source_host VARCHAR(255),
        source_port INTEGER,
        created_at TIMESTAMPTZ DEFAULT NOW()
      );

      CREATE INDEX IF NOT EXISTS idx_correlated_groups_timestamp ON correlated_anomaly_groups(timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_correlated_groups_pattern ON correlated_anomaly_groups(pattern, timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_correlated_groups_severity ON correlated_anomaly_groups(severity, timestamp DESC);

      CREATE TABLE IF NOT EXISTS key_pattern_snapshots (
        id UUID PRIMARY KEY,
        timestamp BIGINT NOT NULL,
        pattern TEXT NOT NULL,
        key_count INTEGER NOT NULL,
        sampled_key_count INTEGER NOT NULL,
        keys_with_ttl INTEGER NOT NULL,
        keys_expiring_soon INTEGER NOT NULL,
        total_memory_bytes BIGINT NOT NULL,
        avg_memory_bytes INTEGER NOT NULL,
        max_memory_bytes INTEGER NOT NULL,
        avg_access_frequency DOUBLE PRECISION,
        hot_key_count INTEGER,
        cold_key_count INTEGER,
        avg_idle_time_seconds DOUBLE PRECISION,
        stale_key_count INTEGER,
        avg_ttl_seconds INTEGER,
        min_ttl_seconds INTEGER,
        max_ttl_seconds INTEGER,
        created_at TIMESTAMPTZ DEFAULT NOW()
      );

      CREATE INDEX IF NOT EXISTS idx_kps_timestamp ON key_pattern_snapshots(timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_kps_pattern ON key_pattern_snapshots(pattern, timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_kps_pattern_timestamp ON key_pattern_snapshots(pattern, timestamp);

      CREATE TABLE IF NOT EXISTS app_settings (
        id INTEGER PRIMARY KEY CHECK (id = 1),
        audit_poll_interval_ms INTEGER NOT NULL DEFAULT 60000,
        client_analytics_poll_interval_ms INTEGER NOT NULL DEFAULT 60000,
        anomaly_poll_interval_ms INTEGER NOT NULL DEFAULT 1000,
        anomaly_cache_ttl_ms INTEGER NOT NULL DEFAULT 3600000,
        anomaly_prometheus_interval_ms INTEGER NOT NULL DEFAULT 30000,
        updated_at BIGINT NOT NULL DEFAULT (EXTRACT(EPOCH FROM NOW()) * 1000)::BIGINT,
        created_at BIGINT NOT NULL DEFAULT (EXTRACT(EPOCH FROM NOW()) * 1000)::BIGINT
      );

      CREATE TABLE IF NOT EXISTS webhooks (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        name VARCHAR(255) NOT NULL,
        url TEXT NOT NULL,
        secret TEXT,
        enabled BOOLEAN DEFAULT true,
        events TEXT[] NOT NULL,
        headers JSONB DEFAULT '{}',
        retry_policy JSONB NOT NULL,
        created_at TIMESTAMPTZ DEFAULT NOW(),
        updated_at TIMESTAMPTZ DEFAULT NOW()
      );

      CREATE TABLE IF NOT EXISTS webhook_deliveries (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        webhook_id UUID NOT NULL REFERENCES webhooks(id) ON DELETE CASCADE,
        event_type VARCHAR(50) NOT NULL,
        payload JSONB NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'pending',
        status_code INT,
        response_body TEXT,
        attempts INT DEFAULT 0,
        next_retry_at TIMESTAMPTZ,
        created_at TIMESTAMPTZ DEFAULT NOW(),
        completed_at TIMESTAMPTZ,
        duration_ms INT
      );

      CREATE INDEX IF NOT EXISTS idx_webhook_deliveries_webhook_id ON webhook_deliveries(webhook_id);
      CREATE INDEX IF NOT EXISTS idx_webhook_deliveries_retry ON webhook_deliveries(status, next_retry_at) WHERE status = 'retrying';

      -- Slow Log Entries Table
      CREATE TABLE IF NOT EXISTS slow_log_entries (
        pk SERIAL PRIMARY KEY,
        slowlog_id BIGINT NOT NULL,
        timestamp BIGINT NOT NULL,
        duration BIGINT NOT NULL,
        command TEXT[] NOT NULL DEFAULT '{}',
        client_address TEXT,
        client_name TEXT,
        captured_at BIGINT NOT NULL,
        source_host TEXT NOT NULL,
        source_port INTEGER NOT NULL,
        UNIQUE(slowlog_id, source_host, source_port)
      );

      CREATE INDEX IF NOT EXISTS idx_slowlog_timestamp ON slow_log_entries(timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_slowlog_command ON slow_log_entries(command);
      CREATE INDEX IF NOT EXISTS idx_slowlog_duration ON slow_log_entries(duration DESC);
      CREATE INDEX IF NOT EXISTS idx_slowlog_client_name ON slow_log_entries(client_name);
      CREATE INDEX IF NOT EXISTS idx_slowlog_captured_at ON slow_log_entries(captured_at DESC);

      -- Command Log Entries Table (Valkey-specific)
      CREATE TABLE IF NOT EXISTS command_log_entries (
        pk SERIAL PRIMARY KEY,
        commandlog_id BIGINT NOT NULL,
        timestamp BIGINT NOT NULL,
        duration BIGINT NOT NULL,
        command TEXT[] NOT NULL DEFAULT '{}',
        client_address TEXT,
        client_name TEXT,
        log_type TEXT NOT NULL,
        captured_at BIGINT NOT NULL,
        source_host TEXT NOT NULL,
        source_port INTEGER NOT NULL,
        UNIQUE(commandlog_id, log_type, source_host, source_port)
      );

      CREATE INDEX IF NOT EXISTS idx_commandlog_timestamp ON command_log_entries(timestamp DESC);
      CREATE INDEX IF NOT EXISTS idx_commandlog_type ON command_log_entries(log_type);
      CREATE INDEX IF NOT EXISTS idx_commandlog_duration ON command_log_entries(duration DESC);
      CREATE INDEX IF NOT EXISTS idx_commandlog_client_name ON command_log_entries(client_name);
      CREATE INDEX IF NOT EXISTS idx_commandlog_captured_at ON command_log_entries(captured_at DESC);
    `);
  }

  async saveAnomalyEvent(event: StoredAnomalyEvent): Promise<string> {
    if (!this.pool) throw new Error('Database not initialized');

    await this.pool.query(
      `INSERT INTO anomaly_events (
        id, timestamp, metric_type, anomaly_type, severity,
        value, baseline, std_dev, z_score, threshold,
        message, correlation_id, related_metrics,
        resolved, resolved_at, duration_ms,
        source_host, source_port
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18)`,
      [
        event.id,
        event.timestamp,
        event.metricType,
        event.anomalyType,
        event.severity,
        event.value,
        event.baseline,
        event.stdDev,
        event.zScore,
        event.threshold,
        event.message,
        event.correlationId || null,
        event.relatedMetrics || [],
        event.resolved,
        event.resolvedAt || null,
        event.durationMs || null,
        event.sourceHost || null,
        event.sourcePort || null,
      ]
    );

    return event.id;
  }

  async saveAnomalyEvents(events: StoredAnomalyEvent[]): Promise<number> {
    if (!this.pool || events.length === 0) return 0;

    const values: any[] = [];
    const placeholders: string[] = [];
    let paramIndex = 1;

    for (const event of events) {
      placeholders.push(`(
        $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++},
        $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++},
        $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++},
        $${paramIndex++}, $${paramIndex++}, $${paramIndex++}
      )`);
      values.push(
        event.id,
        event.timestamp,
        event.metricType,
        event.anomalyType,
        event.severity,
        event.value,
        event.baseline,
        event.stdDev,
        event.zScore,
        event.threshold,
        event.message,
        event.correlationId || null,
        event.relatedMetrics || [],
        event.resolved,
        event.resolvedAt || null,
        event.durationMs || null,
        event.sourceHost || null,
        event.sourcePort || null
      );
    }

    const result = await this.pool.query(
      `INSERT INTO anomaly_events (
        id, timestamp, metric_type, anomaly_type, severity,
        value, baseline, std_dev, z_score, threshold,
        message, correlation_id, related_metrics,
        resolved, resolved_at, duration_ms,
        source_host, source_port
      ) VALUES ${placeholders.join(', ')}`,
      values
    );

    return result.rowCount ?? 0;
  }

  async getAnomalyEvents(options: AnomalyQueryOptions = {}): Promise<StoredAnomalyEvent[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const conditions: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    if (options.startTime) {
      conditions.push(`timestamp >= $${paramIndex++}`);
      params.push(options.startTime);
    }
    if (options.endTime) {
      conditions.push(`timestamp <= $${paramIndex++}`);
      params.push(options.endTime);
    }
    if (options.severity) {
      conditions.push(`severity = $${paramIndex++}`);
      params.push(options.severity);
    }
    if (options.metricType) {
      conditions.push(`metric_type = $${paramIndex++}`);
      params.push(options.metricType);
    }
    if (options.resolved !== undefined) {
      conditions.push(`resolved = $${paramIndex++}`);
      params.push(options.resolved);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';
    const limit = options.limit ?? 100;
    const offset = options.offset ?? 0;

    const result = await this.pool.query(
      `SELECT
        id, timestamp, metric_type, anomaly_type, severity,
        value, baseline, std_dev, z_score, threshold,
        message, correlation_id, related_metrics,
        resolved, resolved_at, duration_ms,
        source_host, source_port
      FROM anomaly_events
      ${whereClause}
      ORDER BY timestamp DESC
      LIMIT $${paramIndex++} OFFSET $${paramIndex++}`,
      [...params, limit, offset]
    );

    return result.rows.map(row => ({
      id: row.id,
      timestamp: parseInt(row.timestamp),
      metricType: row.metric_type,
      anomalyType: row.anomaly_type,
      severity: row.severity,
      value: parseFloat(row.value),
      baseline: parseFloat(row.baseline),
      stdDev: parseFloat(row.std_dev),
      zScore: parseFloat(row.z_score),
      threshold: parseFloat(row.threshold),
      message: row.message,
      correlationId: row.correlation_id,
      relatedMetrics: row.related_metrics,
      resolved: row.resolved,
      resolvedAt: row.resolved_at ? parseInt(row.resolved_at) : undefined,
      durationMs: row.duration_ms ? parseInt(row.duration_ms) : undefined,
      sourceHost: row.source_host,
      sourcePort: row.source_port,
    }));
  }

  async getAnomalyStats(startTime?: number, endTime?: number): Promise<AnomalyStats> {
    if (!this.pool) throw new Error('Database not initialized');

    const conditions: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    if (startTime) {
      conditions.push(`timestamp >= $${paramIndex++}`);
      params.push(startTime);
    }
    if (endTime) {
      conditions.push(`timestamp <= $${paramIndex++}`);
      params.push(endTime);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';

    const totalResult = await this.pool.query(
      `SELECT COUNT(*) as total FROM anomaly_events ${whereClause}`,
      params
    );

    const severityResult = await this.pool.query(
      `SELECT severity, COUNT(*) as count FROM anomaly_events ${whereClause} GROUP BY severity`,
      params
    );

    const metricResult = await this.pool.query(
      `SELECT metric_type, COUNT(*) as count FROM anomaly_events ${whereClause} GROUP BY metric_type`,
      params
    );

    const unresolvedConditions = [...conditions];
    if (unresolvedConditions.length > 0) {
      unresolvedConditions.push(`resolved = false`);
    }
    const unresolvedWhereClause = unresolvedConditions.length > 0
      ? `WHERE ${unresolvedConditions.join(' AND ')}`
      : 'WHERE resolved = false';

    const unresolvedResult = await this.pool.query(
      `SELECT COUNT(*) as count FROM anomaly_events ${unresolvedWhereClause}`,
      params
    );

    const bySeverity: Record<string, number> = {};
    for (const row of severityResult.rows) {
      bySeverity[row.severity] = parseInt(row.count);
    }

    const byMetric: Record<string, number> = {};
    for (const row of metricResult.rows) {
      byMetric[row.metric_type] = parseInt(row.count);
    }

    return {
      totalEvents: parseInt(totalResult.rows[0].total),
      bySeverity,
      byMetric,
      byPattern: {},
      unresolvedCount: parseInt(unresolvedResult.rows[0].count),
    };
  }

  async resolveAnomaly(id: string, resolvedAt: number): Promise<boolean> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      `UPDATE anomaly_events
       SET resolved = true, resolved_at = $2, duration_ms = $2 - timestamp
       WHERE id = $1 AND resolved = false`,
      [id, resolvedAt]
    );

    return (result.rowCount ?? 0) > 0;
  }

  async pruneOldAnomalyEvents(cutoffTimestamp: number): Promise<number> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'DELETE FROM anomaly_events WHERE timestamp < $1',
      [cutoffTimestamp]
    );

    return result.rowCount ?? 0;
  }

  async saveCorrelatedGroup(group: StoredCorrelatedGroup): Promise<string> {
    if (!this.pool) throw new Error('Database not initialized');

    await this.pool.query(
      `INSERT INTO correlated_anomaly_groups (
        correlation_id, timestamp, pattern, severity,
        diagnosis, recommendations, anomaly_count, metric_types,
        source_host, source_port
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
      ON CONFLICT (correlation_id) DO UPDATE SET
        diagnosis = EXCLUDED.diagnosis,
        recommendations = EXCLUDED.recommendations,
        anomaly_count = EXCLUDED.anomaly_count`,
      [
        group.correlationId,
        group.timestamp,
        group.pattern,
        group.severity,
        group.diagnosis,
        group.recommendations,
        group.anomalyCount,
        group.metricTypes,
        group.sourceHost || null,
        group.sourcePort || null,
      ]
    );

    return group.correlationId;
  }

  async getCorrelatedGroups(options: AnomalyQueryOptions = {}): Promise<StoredCorrelatedGroup[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const conditions: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    if (options.startTime) {
      conditions.push(`timestamp >= $${paramIndex++}`);
      params.push(options.startTime);
    }
    if (options.endTime) {
      conditions.push(`timestamp <= $${paramIndex++}`);
      params.push(options.endTime);
    }
    if (options.severity) {
      conditions.push(`severity = $${paramIndex++}`);
      params.push(options.severity);
    }
    if (options.pattern) {
      conditions.push(`pattern = $${paramIndex++}`);
      params.push(options.pattern);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';
    const limit = options.limit ?? 50;
    const offset = options.offset ?? 0;

    const result = await this.pool.query(
      `SELECT
        correlation_id, timestamp, pattern, severity,
        diagnosis, recommendations, anomaly_count, metric_types,
        source_host, source_port
      FROM correlated_anomaly_groups
      ${whereClause}
      ORDER BY timestamp DESC
      LIMIT $${paramIndex++} OFFSET $${paramIndex++}`,
      [...params, limit, offset]
    );

    return result.rows.map(row => ({
      correlationId: row.correlation_id,
      timestamp: parseInt(row.timestamp),
      pattern: row.pattern,
      severity: row.severity,
      diagnosis: row.diagnosis,
      recommendations: row.recommendations,
      anomalyCount: row.anomaly_count,
      metricTypes: row.metric_types,
      sourceHost: row.source_host,
      sourcePort: row.source_port,
    }));
  }

  async pruneOldCorrelatedGroups(cutoffTimestamp: number): Promise<number> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'DELETE FROM correlated_anomaly_groups WHERE timestamp < $1',
      [cutoffTimestamp]
    );

    return result.rowCount ?? 0;
  }

  async saveKeyPatternSnapshots(snapshots: KeyPatternSnapshot[]): Promise<number> {
    if (!this.pool || snapshots.length === 0) return 0;

    const values: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    for (const snapshot of snapshots) {
      values.push(`($${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++})`);
      params.push(
        snapshot.id,
        snapshot.timestamp,
        snapshot.pattern,
        snapshot.keyCount,
        snapshot.sampledKeyCount,
        snapshot.keysWithTtl,
        snapshot.keysExpiringSoon,
        snapshot.totalMemoryBytes,
        snapshot.avgMemoryBytes,
        snapshot.maxMemoryBytes,
        snapshot.avgAccessFrequency ?? null,
        snapshot.hotKeyCount ?? null,
        snapshot.coldKeyCount ?? null,
        snapshot.avgIdleTimeSeconds ?? null,
        snapshot.staleKeyCount ?? null,
        snapshot.avgTtlSeconds ?? null,
        snapshot.minTtlSeconds ?? null,
        snapshot.maxTtlSeconds ?? null,
      );
    }

    await this.pool.query(`
      INSERT INTO key_pattern_snapshots (
        id, timestamp, pattern, key_count, sampled_key_count,
        keys_with_ttl, keys_expiring_soon, total_memory_bytes,
        avg_memory_bytes, max_memory_bytes, avg_access_frequency,
        hot_key_count, cold_key_count, avg_idle_time_seconds,
        stale_key_count, avg_ttl_seconds, min_ttl_seconds, max_ttl_seconds
      ) VALUES ${values.join(', ')}
    `, params);

    return snapshots.length;
  }

  async getKeyPatternSnapshots(options: KeyPatternQueryOptions = {}): Promise<KeyPatternSnapshot[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const conditions: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    if (options.startTime) {
      conditions.push(`timestamp >= $${paramIndex++}`);
      params.push(options.startTime);
    }
    if (options.endTime) {
      conditions.push(`timestamp <= $${paramIndex++}`);
      params.push(options.endTime);
    }
    if (options.pattern) {
      conditions.push(`pattern = $${paramIndex++}`);
      params.push(options.pattern);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';
    const limit = options.limit ?? 100;
    const offset = options.offset ?? 0;

    const result = await this.pool.query(`
      SELECT * FROM key_pattern_snapshots
      ${whereClause}
      ORDER BY timestamp DESC
      LIMIT $${paramIndex++} OFFSET $${paramIndex++}
    `, [...params, limit, offset]);

    return result.rows.map(row => ({
      id: row.id,
      timestamp: parseInt(row.timestamp),
      pattern: row.pattern,
      keyCount: row.key_count,
      sampledKeyCount: row.sampled_key_count,
      keysWithTtl: row.keys_with_ttl,
      keysExpiringSoon: row.keys_expiring_soon,
      totalMemoryBytes: parseInt(row.total_memory_bytes),
      avgMemoryBytes: row.avg_memory_bytes,
      maxMemoryBytes: row.max_memory_bytes,
      avgAccessFrequency: row.avg_access_frequency,
      hotKeyCount: row.hot_key_count,
      coldKeyCount: row.cold_key_count,
      avgIdleTimeSeconds: row.avg_idle_time_seconds,
      staleKeyCount: row.stale_key_count,
      avgTtlSeconds: row.avg_ttl_seconds,
      minTtlSeconds: row.min_ttl_seconds,
      maxTtlSeconds: row.max_ttl_seconds,
    }));
  }

  async getKeyAnalyticsSummary(startTime?: number, endTime?: number): Promise<KeyAnalyticsSummary | null> {
    if (!this.pool) throw new Error('Database not initialized');

    const conditions: string[] = [];
    const params: number[] = [];
    let paramIndex = 1;

    if (startTime) {
      conditions.push(`timestamp >= $${paramIndex++}`);
      params.push(startTime);
    }
    if (endTime) {
      conditions.push(`timestamp <= $${paramIndex++}`);
      params.push(endTime);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';

    const latestSnapshotsResult = await this.pool.query(`
      SELECT pattern, MAX(timestamp) as latest_timestamp
      FROM key_pattern_snapshots
      ${whereClause}
      GROUP BY pattern
    `, params);

    if (latestSnapshotsResult.rows.length === 0) return null;

    const patternConditions = latestSnapshotsResult.rows.map(() => '(pattern = ? AND timestamp = ?)').join(' OR ');
    const patternParams: any[] = [];
    for (const row of latestSnapshotsResult.rows) {
      patternParams.push(row.pattern, row.latest_timestamp);
    }

    let pIdx = 1;
    const patternPlaceholders = latestSnapshotsResult.rows.map(() => `(pattern = $${pIdx++} AND timestamp = $${pIdx++})`).join(' OR ');

    const summaryResult = await this.pool.query(`
      SELECT
        COUNT(DISTINCT pattern) as total_patterns,
        SUM(key_count) as total_keys,
        SUM(total_memory_bytes) as total_memory_bytes,
        SUM(stale_key_count) as stale_key_count,
        SUM(hot_key_count) as hot_key_count,
        SUM(cold_key_count) as cold_key_count,
        SUM(keys_expiring_soon) as keys_expiring_soon
      FROM key_pattern_snapshots
      WHERE ${patternPlaceholders}
    `, patternParams);

    const summary = summaryResult.rows[0];

    const patternRowsResult = await this.pool.query(`
      SELECT pattern, key_count, total_memory_bytes, avg_memory_bytes, stale_key_count, hot_key_count, cold_key_count
      FROM key_pattern_snapshots
      WHERE ${patternPlaceholders}
    `, patternParams);

    const byPattern: Record<string, any> = {};
    for (const row of patternRowsResult.rows) {
      byPattern[row.pattern] = {
        keyCount: row.key_count,
        memoryBytes: parseInt(row.total_memory_bytes),
        avgMemoryBytes: row.avg_memory_bytes,
        staleCount: row.stale_key_count ?? 0,
        hotCount: row.hot_key_count ?? 0,
        coldCount: row.cold_key_count ?? 0,
      };
    }

    const timeRangeResult = await this.pool.query(`
      SELECT MIN(timestamp) as earliest, MAX(timestamp) as latest
      FROM key_pattern_snapshots ${whereClause}
    `, params);

    const timeRange = timeRangeResult.rows[0].earliest !== null && timeRangeResult.rows[0].latest !== null
      ? { earliest: parseInt(timeRangeResult.rows[0].earliest), latest: parseInt(timeRangeResult.rows[0].latest) }
      : null;

    return {
      totalPatterns: parseInt(summary.total_patterns) || 0,
      totalKeys: parseInt(summary.total_keys) || 0,
      totalMemoryBytes: parseInt(summary.total_memory_bytes) || 0,
      staleKeyCount: parseInt(summary.stale_key_count) || 0,
      hotKeyCount: parseInt(summary.hot_key_count) || 0,
      coldKeyCount: parseInt(summary.cold_key_count) || 0,
      keysExpiringSoon: parseInt(summary.keys_expiring_soon) || 0,
      byPattern,
      timeRange,
    };
  }

  async getKeyPatternTrends(pattern: string, startTime: number, endTime: number): Promise<Array<{
    timestamp: number;
    keyCount: number;
    memoryBytes: number;
    staleCount: number;
  }>> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(`
      SELECT timestamp, key_count, total_memory_bytes, stale_key_count
      FROM key_pattern_snapshots
      WHERE pattern = $1 AND timestamp >= $2 AND timestamp <= $3
      ORDER BY timestamp ASC
    `, [pattern, startTime, endTime]);

    return result.rows.map(row => ({
      timestamp: parseInt(row.timestamp),
      keyCount: row.key_count,
      memoryBytes: parseInt(row.total_memory_bytes),
      staleCount: row.stale_key_count ?? 0,
    }));
  }

  async pruneOldKeyPatternSnapshots(cutoffTimestamp: number): Promise<number> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'DELETE FROM key_pattern_snapshots WHERE timestamp < $1',
      [cutoffTimestamp]
    );

    return result.rowCount ?? 0;
  }

  async getSettings(): Promise<AppSettings | null> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query('SELECT * FROM app_settings WHERE id = 1');

    if (result.rows.length === 0) {
      return null;
    }

    const row = result.rows[0];
    return {
      id: row.id,
      auditPollIntervalMs: row.audit_poll_interval_ms,
      clientAnalyticsPollIntervalMs: row.client_analytics_poll_interval_ms,
      anomalyPollIntervalMs: row.anomaly_poll_interval_ms,
      anomalyCacheTtlMs: row.anomaly_cache_ttl_ms,
      anomalyPrometheusIntervalMs: row.anomaly_prometheus_interval_ms,
      updatedAt: parseInt(row.updated_at),
      createdAt: parseInt(row.created_at),
    };
  }

  async saveSettings(settings: AppSettings): Promise<AppSettings> {
    if (!this.pool) throw new Error('Database not initialized');

    const now = Date.now();
    await this.pool.query(
      `INSERT INTO app_settings (
        id, audit_poll_interval_ms, client_analytics_poll_interval_ms,
        anomaly_poll_interval_ms, anomaly_cache_ttl_ms, anomaly_prometheus_interval_ms,
        updated_at, created_at
      ) VALUES (1, $1, $2, $3, $4, $5, $6, $7)
      ON CONFLICT(id) DO UPDATE SET
        audit_poll_interval_ms = EXCLUDED.audit_poll_interval_ms,
        client_analytics_poll_interval_ms = EXCLUDED.client_analytics_poll_interval_ms,
        anomaly_poll_interval_ms = EXCLUDED.anomaly_poll_interval_ms,
        anomaly_cache_ttl_ms = EXCLUDED.anomaly_cache_ttl_ms,
        anomaly_prometheus_interval_ms = EXCLUDED.anomaly_prometheus_interval_ms,
        updated_at = EXCLUDED.updated_at`,
      [
        settings.auditPollIntervalMs,
        settings.clientAnalyticsPollIntervalMs,
        settings.anomalyPollIntervalMs,
        settings.anomalyCacheTtlMs,
        settings.anomalyPrometheusIntervalMs,
        now,
        settings.createdAt || now
      ]
    );

    const saved = await this.getSettings();
    if (!saved) {
      throw new Error('Failed to save settings');
    }
    return saved;
  }

  async updateSettings(updates: SettingsUpdateRequest): Promise<AppSettings> {
    if (!this.pool) throw new Error('Database not initialized');

    const current = await this.getSettings();
    if (!current) {
      throw new Error('Settings not found. Initialize settings first.');
    }

    const merged: AppSettings = {
      ...current,
      ...updates,
      updatedAt: Date.now(),
    };

    return this.saveSettings(merged);
  }

  async createWebhook(webhook: Omit<Webhook, 'id' | 'createdAt' | 'updatedAt'>): Promise<Webhook> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      `INSERT INTO webhooks (name, url, secret, enabled, events, headers, retry_policy)
       VALUES ($1, $2, $3, $4, $5, $6, $7)
       RETURNING *`,
      [
        webhook.name,
        webhook.url,
        webhook.secret,
        webhook.enabled,
        webhook.events,
        JSON.stringify(webhook.headers || {}),
        JSON.stringify(webhook.retryPolicy),
      ]
    );

    const row = result.rows[0];
    return {
      id: row.id,
      name: row.name,
      url: row.url,
      secret: row.secret,
      enabled: row.enabled,
      events: row.events,
      headers: row.headers,
      retryPolicy: row.retry_policy,
      createdAt: new Date(row.created_at).getTime(),
      updatedAt: new Date(row.updated_at).getTime(),
    };
  }

  async getWebhook(id: string): Promise<Webhook | null> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query('SELECT * FROM webhooks WHERE id = $1', [id]);
    if (result.rows.length === 0) return null;

    const row = result.rows[0];
    return {
      id: row.id,
      name: row.name,
      url: row.url,
      secret: row.secret,
      enabled: row.enabled,
      events: row.events,
      headers: row.headers,
      retryPolicy: row.retry_policy,
      createdAt: new Date(row.created_at).getTime(),
      updatedAt: new Date(row.updated_at).getTime(),
    };
  }

  async getWebhooksByInstance(): Promise<Webhook[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query('SELECT * FROM webhooks ORDER BY created_at DESC');
    return result.rows.map(row => ({
      id: row.id,
      name: row.name,
      url: row.url,
      secret: row.secret,
      enabled: row.enabled,
      events: row.events,
      headers: row.headers,
      retryPolicy: row.retry_policy,
      createdAt: new Date(row.created_at).getTime(),
      updatedAt: new Date(row.updated_at).getTime(),
    }));
  }

  async getWebhooksByEvent(event: WebhookEventType): Promise<Webhook[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'SELECT * FROM webhooks WHERE enabled = true AND $1 = ANY(events)',
      [event]
    );

    return result.rows.map(row => ({
      id: row.id,
      name: row.name,
      url: row.url,
      secret: row.secret,
      enabled: row.enabled,
      events: row.events,
      headers: row.headers,
      retryPolicy: row.retry_policy,
      createdAt: new Date(row.created_at).getTime(),
      updatedAt: new Date(row.updated_at).getTime(),
    }));
  }

  async updateWebhook(id: string, updates: Partial<Omit<Webhook, 'id' | 'createdAt' | 'updatedAt'>>): Promise<Webhook | null> {
    if (!this.pool) throw new Error('Database not initialized');

    const setClauses: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    if (updates.name !== undefined) {
      setClauses.push(`name = $${paramIndex++}`);
      params.push(updates.name);
    }
    if (updates.url !== undefined) {
      setClauses.push(`url = $${paramIndex++}`);
      params.push(updates.url);
    }
    if (updates.secret !== undefined) {
      setClauses.push(`secret = $${paramIndex++}`);
      params.push(updates.secret);
    }
    if (updates.enabled !== undefined) {
      setClauses.push(`enabled = $${paramIndex++}`);
      params.push(updates.enabled);
    }
    if (updates.events !== undefined) {
      setClauses.push(`events = $${paramIndex++}`);
      params.push(updates.events);
    }
    if (updates.headers !== undefined) {
      setClauses.push(`headers = $${paramIndex++}`);
      params.push(JSON.stringify(updates.headers));
    }
    if (updates.retryPolicy !== undefined) {
      setClauses.push(`retry_policy = $${paramIndex++}`);
      params.push(JSON.stringify(updates.retryPolicy));
    }

    if (setClauses.length === 0) {
      return this.getWebhook(id);
    }

    setClauses.push(`updated_at = NOW()`);
    params.push(id);

    const result = await this.pool.query(
      `UPDATE webhooks SET ${setClauses.join(', ')} WHERE id = $${paramIndex} RETURNING *`,
      params
    );

    if (result.rows.length === 0) return null;

    const row = result.rows[0];
    return {
      id: row.id,
      name: row.name,
      url: row.url,
      secret: row.secret,
      enabled: row.enabled,
      events: row.events,
      headers: row.headers,
      retryPolicy: row.retry_policy,
      createdAt: new Date(row.created_at).getTime(),
      updatedAt: new Date(row.updated_at).getTime(),
    };
  }

  async deleteWebhook(id: string): Promise<boolean> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query('DELETE FROM webhooks WHERE id = $1', [id]);
    return (result.rowCount ?? 0) > 0;
  }

  async createDelivery(delivery: Omit<WebhookDelivery, 'id' | 'createdAt'>): Promise<WebhookDelivery> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      `INSERT INTO webhook_deliveries (
        webhook_id, event_type, payload, status, status_code, response_body,
        attempts, next_retry_at, completed_at, duration_ms
      )
      VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
      RETURNING *`,
      [
        delivery.webhookId,
        delivery.eventType,
        JSON.stringify(delivery.payload),
        delivery.status,
        delivery.statusCode || null,
        delivery.responseBody || null,
        delivery.attempts,
        delivery.nextRetryAt ? new Date(delivery.nextRetryAt) : null,
        delivery.completedAt ? new Date(delivery.completedAt) : null,
        delivery.durationMs || null,
      ]
    );

    const row = result.rows[0];
    return {
      id: row.id,
      webhookId: row.webhook_id,
      eventType: row.event_type,
      payload: row.payload,
      status: row.status,
      statusCode: row.status_code,
      responseBody: row.response_body,
      attempts: row.attempts,
      nextRetryAt: row.next_retry_at ? new Date(row.next_retry_at).getTime() : undefined,
      createdAt: new Date(row.created_at).getTime(),
      completedAt: row.completed_at ? new Date(row.completed_at).getTime() : undefined,
      durationMs: row.duration_ms,
    };
  }

  async getDelivery(id: string): Promise<WebhookDelivery | null> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query('SELECT * FROM webhook_deliveries WHERE id = $1', [id]);
    if (result.rows.length === 0) return null;

    const row = result.rows[0];
    return {
      id: row.id,
      webhookId: row.webhook_id,
      eventType: row.event_type,
      payload: row.payload,
      status: row.status,
      statusCode: row.status_code,
      responseBody: row.response_body,
      attempts: row.attempts,
      nextRetryAt: row.next_retry_at ? new Date(row.next_retry_at).getTime() : undefined,
      createdAt: new Date(row.created_at).getTime(),
      completedAt: row.completed_at ? new Date(row.completed_at).getTime() : undefined,
      durationMs: row.duration_ms,
    };
  }

  async getDeliveriesByWebhook(webhookId: string, limit: number = 50, offset: number = 0): Promise<WebhookDelivery[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'SELECT * FROM webhook_deliveries WHERE webhook_id = $1 ORDER BY created_at DESC LIMIT $2 OFFSET $3',
      [webhookId, limit, offset]
    );

    return result.rows.map(row => ({
      id: row.id,
      webhookId: row.webhook_id,
      eventType: row.event_type,
      payload: row.payload,
      status: row.status,
      statusCode: row.status_code,
      responseBody: row.response_body,
      attempts: row.attempts,
      nextRetryAt: row.next_retry_at ? new Date(row.next_retry_at).getTime() : undefined,
      createdAt: new Date(row.created_at).getTime(),
      completedAt: row.completed_at ? new Date(row.completed_at).getTime() : undefined,
      durationMs: row.duration_ms,
    }));
  }

  async updateDelivery(id: string, updates: Partial<Omit<WebhookDelivery, 'id' | 'webhookId' | 'createdAt'>>): Promise<boolean> {
    if (!this.pool) throw new Error('Database not initialized');

    const setClauses: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    if (updates.status !== undefined) {
      setClauses.push(`status = $${paramIndex++}`);
      params.push(updates.status);
    }
    if (updates.statusCode !== undefined) {
      setClauses.push(`status_code = $${paramIndex++}`);
      params.push(updates.statusCode);
    }
    if (updates.responseBody !== undefined) {
      setClauses.push(`response_body = $${paramIndex++}`);
      params.push(updates.responseBody);
    }
    if (updates.attempts !== undefined) {
      setClauses.push(`attempts = $${paramIndex++}`);
      params.push(updates.attempts);
    }
    if (updates.nextRetryAt !== undefined) {
      setClauses.push(`next_retry_at = $${paramIndex++}`);
      params.push(updates.nextRetryAt ? new Date(updates.nextRetryAt) : null);
    }
    if (updates.completedAt !== undefined) {
      setClauses.push(`completed_at = $${paramIndex++}`);
      params.push(updates.completedAt ? new Date(updates.completedAt) : null);
    }
    if (updates.durationMs !== undefined) {
      setClauses.push(`duration_ms = $${paramIndex++}`);
      params.push(updates.durationMs);
    }

    if (setClauses.length === 0) return true;

    params.push(id);

    const result = await this.pool.query(
      `UPDATE webhook_deliveries SET ${setClauses.join(', ')} WHERE id = $${paramIndex}`,
      params
    );

    return (result.rowCount ?? 0) > 0;
  }

  async getRetriableDeliveries(limit: number = 100): Promise<WebhookDelivery[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      `SELECT * FROM webhook_deliveries
       WHERE status = 'retrying'
       AND next_retry_at <= EXTRACT(EPOCH FROM NOW()) * 1000
       ORDER BY next_retry_at ASC
       LIMIT $1
       FOR UPDATE SKIP LOCKED`,
      [limit]
    );

    return result.rows.map(row => ({
      id: row.id,
      webhookId: row.webhook_id,
      eventType: row.event_type,
      payload: row.payload,
      status: row.status,
      statusCode: row.status_code,
      responseBody: row.response_body,
      attempts: row.attempts,
      nextRetryAt: row.next_retry_at ? new Date(row.next_retry_at).getTime() : undefined,
      createdAt: new Date(row.created_at).getTime(),
      completedAt: row.completed_at ? new Date(row.completed_at).getTime() : undefined,
      durationMs: row.duration_ms,
    }));
  }

  async pruneOldDeliveries(cutoffTimestamp: number): Promise<number> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'DELETE FROM webhook_deliveries WHERE EXTRACT(EPOCH FROM created_at) * 1000 < $1',
      [cutoffTimestamp]
    );

    return result.rowCount ?? 0;
  }

  // Slow Log Methods
  async saveSlowLogEntries(entries: StoredSlowLogEntry[]): Promise<number> {
    if (!this.pool || entries.length === 0) return 0;

    const values: any[] = [];
    const placeholders: string[] = [];
    let paramIndex = 1;

    for (const entry of entries) {
      placeholders.push(`(
        $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++},
        $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++}
      )`);
      values.push(
        entry.id,
        entry.timestamp,
        entry.duration,
        entry.command,  // PostgreSQL will accept string[] for TEXT[]
        entry.clientAddress || '',
        entry.clientName || '',
        entry.capturedAt,
        entry.sourceHost,
        entry.sourcePort,
      );
    }

    const query = `
      INSERT INTO slow_log_entries (
        slowlog_id, timestamp, duration, command,
        client_address, client_name, captured_at, source_host, source_port
      ) VALUES ${placeholders.join(', ')}
      ON CONFLICT (slowlog_id, source_host, source_port) DO NOTHING
    `;

    const result = await this.pool.query(query, values);
    return result.rowCount ?? 0;
  }

  async getSlowLogEntries(options: SlowLogQueryOptions = {}): Promise<StoredSlowLogEntry[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const conditions: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    if (options.startTime) {
      conditions.push(`timestamp >= $${paramIndex++}`);
      params.push(options.startTime);
    }
    if (options.endTime) {
      conditions.push(`timestamp <= $${paramIndex++}`);
      params.push(options.endTime);
    }
    if (options.command) {
      // Search in the first element of command array (the command name)
      conditions.push(`command[1] ILIKE $${paramIndex++}`);
      params.push(`%${options.command}%`);
    }
    if (options.clientName) {
      conditions.push(`client_name ILIKE $${paramIndex++}`);
      params.push(`%${options.clientName}%`);
    }
    if (options.minDuration) {
      conditions.push(`duration >= $${paramIndex++}`);
      params.push(options.minDuration);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';
    const limit = options.limit ?? 100;
    const offset = options.offset ?? 0;

    const result = await this.pool.query(
      `SELECT
        slowlog_id, timestamp, duration, command,
        client_address, client_name, captured_at, source_host, source_port
      FROM slow_log_entries
      ${whereClause}
      ORDER BY timestamp DESC
      LIMIT $${paramIndex++} OFFSET $${paramIndex++}`,
      [...params, limit, offset]
    );

    return result.rows.map(row => ({
      id: parseInt(row.slowlog_id),
      timestamp: parseInt(row.timestamp),
      duration: parseInt(row.duration),
      command: row.command || [],
      clientAddress: row.client_address,
      clientName: row.client_name,
      capturedAt: parseInt(row.captured_at),
      sourceHost: row.source_host,
      sourcePort: row.source_port,
    }));
  }

  async getLatestSlowLogId(): Promise<number | null> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'SELECT MAX(slowlog_id) as max_id FROM slow_log_entries'
    );

    const maxId = result.rows[0]?.max_id;
    return maxId !== null && maxId !== undefined ? Number(maxId) : null;
  }

  async pruneOldSlowLogEntries(cutoffTimestamp: number): Promise<number> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'DELETE FROM slow_log_entries WHERE captured_at < $1',
      [cutoffTimestamp]
    );

    return result.rowCount ?? 0;
  }

  // Command Log Methods (Valkey-specific)
  async saveCommandLogEntries(entries: StoredCommandLogEntry[]): Promise<number> {
    if (!this.pool || entries.length === 0) return 0;

    const values: any[] = [];
    const placeholders: string[] = [];
    let paramIndex = 1;

    for (const entry of entries) {
      placeholders.push(`(
        $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++},
        $${paramIndex++}, $${paramIndex++}, $${paramIndex++}, $${paramIndex++},
        $${paramIndex++}, $${paramIndex++}
      )`);
      values.push(
        entry.id,
        entry.timestamp,
        entry.duration,
        entry.command,
        entry.clientAddress || '',
        entry.clientName || '',
        entry.type,
        entry.capturedAt,
        entry.sourceHost,
        entry.sourcePort,
      );
    }

    const query = `
      INSERT INTO command_log_entries (
        commandlog_id, timestamp, duration, command,
        client_address, client_name, log_type, captured_at, source_host, source_port
      ) VALUES ${placeholders.join(', ')}
      ON CONFLICT (commandlog_id, log_type, source_host, source_port) DO NOTHING
    `;

    const result = await this.pool.query(query, values);
    return result.rowCount ?? 0;
  }

  async getCommandLogEntries(options: CommandLogQueryOptions = {}): Promise<StoredCommandLogEntry[]> {
    if (!this.pool) throw new Error('Database not initialized');

    const conditions: string[] = [];
    const params: any[] = [];
    let paramIndex = 1;

    if (options.startTime) {
      conditions.push(`timestamp >= $${paramIndex++}`);
      params.push(options.startTime);
    }
    if (options.endTime) {
      conditions.push(`timestamp <= $${paramIndex++}`);
      params.push(options.endTime);
    }
    if (options.command) {
      conditions.push(`command[1] ILIKE $${paramIndex++}`);
      params.push(`%${options.command}%`);
    }
    if (options.clientName) {
      conditions.push(`client_name ILIKE $${paramIndex++}`);
      params.push(`%${options.clientName}%`);
    }
    if (options.type) {
      conditions.push(`log_type = $${paramIndex++}`);
      params.push(options.type);
    }
    if (options.minDuration) {
      conditions.push(`duration >= $${paramIndex++}`);
      params.push(options.minDuration);
    }

    const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';
    const limit = options.limit ?? 100;
    const offset = options.offset ?? 0;

    const result = await this.pool.query(
      `SELECT
        commandlog_id, timestamp, duration, command,
        client_address, client_name, log_type, captured_at, source_host, source_port
      FROM command_log_entries
      ${whereClause}
      ORDER BY timestamp DESC
      LIMIT $${paramIndex++} OFFSET $${paramIndex++}`,
      [...params, limit, offset]
    );

    return result.rows.map(row => ({
      id: parseInt(row.commandlog_id),
      timestamp: parseInt(row.timestamp),
      duration: parseInt(row.duration),
      command: row.command || [],
      clientAddress: row.client_address,
      clientName: row.client_name,
      type: row.log_type as CommandLogType,
      capturedAt: parseInt(row.captured_at),
      sourceHost: row.source_host,
      sourcePort: row.source_port,
    }));
  }

  async getLatestCommandLogId(type: CommandLogType): Promise<number | null> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'SELECT MAX(commandlog_id) as max_id FROM command_log_entries WHERE log_type = $1',
      [type]
    );

    const maxId = result.rows[0]?.max_id;
    return maxId !== null && maxId !== undefined ? Number(maxId) : null;
  }

  async pruneOldCommandLogEntries(cutoffTimestamp: number): Promise<number> {
    if (!this.pool) throw new Error('Database not initialized');

    const result = await this.pool.query(
      'DELETE FROM command_log_entries WHERE captured_at < $1',
      [cutoffTimestamp]
    );

    return result.rowCount ?? 0;
  }
}
